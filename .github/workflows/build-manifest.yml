name: Build photos (resize + manifest)

permissions:
  contents: write

on:
  push:
    paths:
      - 'img/originals/*.jpg'
      - 'img/originals/*.jpeg'
      - 'img/originals/*.JPG'
      - 'img/originals/*.JPEG'
      - '.github/workflows/build-manifest.yml'
  workflow_dispatch:

concurrency:
  group: build-photos
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: true
          fetch-depth: 0  # need full history for git log timestamps

      - name: Install ImageMagick
        run: |
          sudo apt-get update
          sudo apt-get install -y imagemagick

      - name: Ensure ImageMagick is available
        run: convert -version

      - name: Resize originals into 640/1280/2560
        shell: bash
        run: |
          set -euo pipefail
          shopt -s nullglob nocaseglob
          mkdir -p img img/originals
          for f in img/originals/*.{jpg,jpeg,JPG,JPEG}; do
            [ -e "$f" ] || continue
            stem="$(basename "${f%.*}")"
            for size in 640 1280 2560; do
              out="img/${stem}-${size}.jpg"
              if [[ ! -f "$out" ]]; then
                convert "$f" -auto-orient -strip -resize "${size}x${size}>" -quality 88 "$out"
                echo "Wrote $out"
              fi
            done
          done

      - name: Fetch metadata CSV from Google Sheets
        env:
          SHEET_CSV_URL: ${{ secrets.SHEET_CSV_URL }}
        run: |
          set -euo pipefail
          if [ -z "${SHEET_CSV_URL:-}" ]; then
            echo "SHEET_CSV_URL secret is not set"; exit 1
          fi
          curl -fsSL "$SHEET_CSV_URL" -o sheet.csv
          echo "Downloaded sheet.csv ($(wc -c < sheet.csv) bytes)"

      - name: Build img/photos.json by merging CSV metadata
        shell: bash
        run: |
          set -euo pipefail
          python3 - << 'PY'
          import csv, json, os, subprocess, sys, re
          from datetime import datetime

          # Helpers
          def git_ts(path):
            try:
              # ISO 8601 commit time of last change to this path
              return subprocess.check_output(
                ["git","log","-1","--format=%cI","--",path],
                text=True
              ).strip()
            except subprocess.CalledProcessError:
              return ""

          def find_original(base):
            # return the first existing original path for this base
            for ext in (".jpg",".jpeg",".JPG",".JPEG"):
              p = os.path.join("img","originals", base + ext)
              if os.path.isfile(p):
                return p
            return None

          def has_resized(base):
            return all(os.path.isfile(os.path.join("img", f"{base}-{s}.jpg")) for s in (640,1280,2560))

          def parse_date(s):
            # Accept YYYY-MM-DD (preferred). Return datetime or None.
            if not s: return None
            try:
              return datetime.strptime(s.strip(), "%Y-%m-%d")
            except ValueError:
              return None

          # Load CSV (tolerant header names)
          meta = {}
          if os.path.isfile("sheet.csv") and os.path.getsize("sheet.csv") > 0:
            with open("sheet.csv", newline="", encoding="utf-8") as f:
              reader = csv.DictReader(f)
              # normalize headers
              def norm(k): return (k or "").strip().lower()
              for row in reader:
                row_n = { norm(k): (v or "").strip() for k,v in row.items() }
                b = row_n.get("base") or row_n.get("id") or row_n.get("filename") or ""
                b = re.sub(r"\.(jpg|jpeg)$","", b, flags=re.IGNORECASE).strip()
                if not b: continue
                # Keep the latest occurrence (later rows override earlier)
                meta[b] = {
                  "title":     row_n.get("title","") or b,
                  "date":      row_n.get("date",""),     # YYYY-MM-DD preferred
                  "camera":    row_n.get("camera",""),
                  "lens":      row_n.get("lens",""),
                  "film":      row_n.get("film",""),
                  "location":  row_n.get("location",""),
                  "overlay":   row_n.get("overlay",""),
                  "alt":       row_n.get("alt",""),
                  # any tags column, comma/space separated
                  "tags": [t for t in re.split(r"[;,]\s*|\s{2,}", row_n.get("tags","")) if t] if "tags" in row_n else []
                }

          # Walk originals (dedupe by base)
          seen = set()
          entries = []
          originals_dir = os.path.join("img","originals")
          for name in os.listdir(originals_dir) if os.path.isdir(originals_dir) else []:
            root, ext = os.path.splitext(name)
            if ext.lower() not in (".jpg",".jpeg"): continue
            base = root
            if base in seen: continue
            seen.add(base)

            if not has_resized(base):
              # Skip until resized variants exist (first step handles this)
              continue

            m = meta.get(base, {})
            title = m.get("title") or base
            alt   = m.get("alt") or title or base
            overlay = m.get("overlay") or base

            # Prefer "date" from sheet; else blank
            date_str = (m.get("date") or "").strip()
            date_dt = parse_date(date_str)

            # ts (for ordering): prefer sheet date at 00:00Z; else commit time of original; else commit of -640; else ""
            ts = ""
            if date_dt:
              ts = date_dt.strftime("%Y-%m-%dT00:00:00Z")
            else:
              orig = find_original(base)
              ts = git_ts(orig) if orig else ""
              if not ts:
                ts = git_ts(os.path.join("img", f"{base}-640.jpg"))

            # Presentational date: sheet date if valid, else derive from ts if present
            if not date_dt and ts:
              try:
                date_dt = datetime.fromisoformat(ts.replace("Z","+00:00")).date()
                date_str = date_dt.isoformat()
              except Exception:
                date_str = ""

            entry = {
              "base": base,
              "title": title,
              "overlay": overlay,
              "alt": alt,
              "date": date_str,   # taken date from sheet (preferred)
              "ts": ts,           # for ordering fallback
              "camera":   m.get("camera",""),
              "lens":     m.get("lens",""),
              "film":     m.get("film",""),
              "location": m.get("location",""),
              "tags":     m.get("tags",[])
            }
            entries.append(entry)

          # Sort newest-first: date (if present) then ts
          def sort_key(e):
            # try date first
            d = parse_date(e.get("date",""))
            if d: return (d, e.get("ts",""))
            # else ts
            t = e.get("ts","")
            try:
              return (datetime.fromisoformat(t.replace("Z","+00:00")), t)
            except Exception:
              return (datetime.min, "")
          entries.sort(key=sort_key, reverse=True)

          # Write JSON
          os.makedirs("img", exist_ok=True)
          with open(os.path.join("img","photos.json"), "w", encoding="utf-8") as f:
            json.dump(entries, f, ensure_ascii=False, indent=2)
          print(f"Wrote img/photos.json with {len(entries)} entries")
          PY

      - name: Commit and push generated files safely
        shell: bash
        run: |
          set -euo pipefail
          git config user.name  "actions-bot"
          git config user.email "actions@users.noreply.github.com"

          git pull --rebase --autostash

          git add img/*.jpg img/photos.json 2>/dev/null || true
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "Resize photos + update manifest (merged with sheet CSV)"
          if ! git push; then
            git pull --rebase --autostash
            git push
          fi
