name: Build photos (resize + manifest)

permissions:
  contents: write

on:
  push:
    paths:
      - 'img/originals/*.jpg'
      - 'img/originals/*.jpeg'
      - 'img/originals/*.JPG'
      - 'img/originals/*.JPEG'
      - '.github/workflows/build-manifest.yml'
  workflow_dispatch:

concurrency:
  group: build-photos
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: true
          fetch-depth: 0  # ensure git log has full history

      - name: Install ImageMagick
        run: |
          sudo apt-get update
          sudo apt-get install -y imagemagick

      - name: Ensure ImageMagick is available
        run: convert -version

      - name: Resize originals into 640/1280/2560
        shell: bash
        run: |
          set -euo pipefail
          shopt -s nullglob nocaseglob
          mkdir -p img img/originals
          for f in img/originals/*.{jpg,jpeg,JPG,JPEG}; do
            [ -e "$f" ] || continue
            stem="$(basename "${f%.*}")"
            for size in 640 1280 2560; do
              out="img/${stem}-${size}.jpg"
              if [[ ! -f "$out" ]]; then
                convert "$f" -auto-orient -strip -resize "${size}x${size}>" -quality 88 "$out"
                echo "Wrote $out"
              fi
            done
          done

      - name: Build img/photos.json from originals (newest first)
        shell: bash
        run: |
          set -euo pipefail

          # Collect "<ISO8601> <stem>" for all originals
          mapfile -t LINES < <(
            shopt -s nullglob nocaseglob
            for f in img/originals/*.{jpg,jpeg,JPG,JPEG}; do
              stem="$(basename "${f%.*}")"
              ts="$(git log -1 --format=%cI -- "$f" 2>/dev/null || echo 1970-01-01T00:00:00Z)"
              echo "$ts $stem"
            done | LC_ALL=C sort -r
          )

          # De-duplicate by stem, keeping the first (newest) timestamped line
          mapfile -t UNIQUE < <(printf "%s\n" "${LINES[@]}" | awk '!seen[$2]++')

          # Build photos.json
          : > img/photos.json
          echo "[" >> img/photos.json
          first=1
          for line in "${UNIQUE[@]}"; do
            ts="${line%% *}"
            b="${line#* }"
            if [[ -f "img/${b}-640.jpg" && -f "img/${b}-1280.jpg" && -f "img/${b}-2560.jpg" ]]; then
              date_short="${ts%%T*}"
              if [[ $first -eq 0 ]]; then echo "," >> img/photos.json; fi
              first=0
              printf '  {"base":"%s","title":"%s","overlay":"%s","alt":"%s","date":"%s","ts":"%s"}' \
                "$b" "$b" "$b" "$b" "$date_short" "$ts" >> img/photos.json
            fi
          done
          echo ""  >> img/photos.json
          echo "]" >> img/photos.json

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Google Sheets client
        run: pip install --quiet google-api-python-client google-auth-httplib2 google-auth-oauthlib

      - name: Merge metadata from Google Sheet into photos.json
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_SHEETS_CREDENTIALS }}
          SHEET_ID: ${{ secrets.SHEET_ID }}
        shell: bash
        run: |
          python - <<'PY'
          import json, os, sys, pathlib
          from google.oauth2 import service_account
          from googleapiclient.discovery import build

          ROOT = pathlib.Path(__file__).resolve().parents[2]  # repo root
          photos_path = ROOT / "img" / "photos.json"

          # Load current photos.json (already created earlier in your job)
          with open(photos_path, "r", encoding="utf-8") as f:
            photos = json.load(f)

          # Auth to Sheets
          info = json.loads(os.environ["GOOGLE_CREDENTIALS"])
          creds = service_account.Credentials.from_service_account_info(
              info,
              scopes=["https://www.googleapis.com/auth/spreadsheets.readonly"]
          )
          service = build("sheets", "v4", credentials=creds)

          # Read rows from the "Photos" sheet
          SHEET_ID = os.environ["SHEET_ID"]
          rng = "Photos!A:Z"
          resp = service.spreadsheets().values().get(spreadsheetId=SHEET_ID, range=rng).execute()
          rows = resp.get("values", [])

          if not rows:
            print("No rows found in Google Sheet; leaving photos.json unchanged.")
            sys.exit(0)

          # Build a lookup from header row
          headers = [h.strip().lower() for h in rows[0]]
          idx = {h:i for i,h in enumerate(headers)}

          def val(row, key):
            i = idx.get(key)
            return (row[i].strip() if i is not None and i < len(row) else "")

          # Convert sheet to dict keyed by base
          sheet = {}
          for row in rows[1:]:
            base = val(row, "base")
            if not base:
              continue
            sheet[base] = {
              "title":    val(row, "title")    or None,
              "date":     val(row, "date")     or None,   # taken date you want displayed
              "camera":   val(row, "camera")   or None,
              "lens":     val(row, "lens")     or None,
              "film":     val(row, "film")     or None,
              "location": val(row, "location") or None,
              "tags":     [t.strip() for t in val(row, "tags").split(",")] if val(row, "tags") else None
            }

          # Merge: for each photo in JSON, override from sheet if present
          by_base = {p["base"]: p for p in photos}
          for base, meta in sheet.items():
            p = by_base.get(base)
            if not p:
              # Optional: if a row exists for an image not yet generated, skip
              continue
            # Update fields when provided
            if meta["title"]    is not None: p["title"]    = meta["title"]
            if meta["date"]     is not None: p["date"]     = meta["date"]  # replaces commit date
            if meta["camera"]   is not None: p["camera"]   = meta["camera"]
            if meta["lens"]     is not None: p["lens"]     = meta["lens"]
            if meta["film"]     is not None: p["film"]     = meta["film"]
            if meta["location"] is not None: p["location"] = meta["location"]
            if meta["tags"]     is not None: p["tags"]     = meta["tags"]

          # Write back
          with open(photos_path, "w", encoding="utf-8") as f:
            json.dump(photos, f, ensure_ascii=False, indent=2)
            f.write("\n")
          print("Merged sheet metadata into img/photos.json")
          PY
      

      - name: Commit and push generated files safely
        shell: bash
        run: |
          set -euo pipefail
          git config user.name  "actions-bot"
          git config user.email "actions@users.noreply.github.com"

          git pull --rebase --autostash

          git add img/*.jpg img/photos.json 2>/dev/null || true
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "Resize photos + update manifest"

          if ! git push; then
            git pull --rebase --autostash
            git push
          fi
